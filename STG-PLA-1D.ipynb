{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "Note: data is the three scale channel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "load_path='F:/NISTdata_H/Active Mobile/AAPlantD1_2GHz_TX1_hpol_run4_pp.mat'\n",
    "load_mat=h5py.File(load_path,'r')\n",
    "IQdata=load_mat['IQdata'][3600:21600,0:256].view('complex')\n",
    "locations=60\n",
    "records=300\n",
    "# load_path='F:/NISTdata_H/Active Mobile/AAPlantD3_2GHz_TX2b_vpol_run32_pp.mat'  # 3900:39900 120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][3900:21900,0:256].view('complex')\n",
    "# locations=60\n",
    "# records=300\n",
    "# load_path='F:/NISTdata_H/Active Mobile/AAPlantD3_2GHz_TX2b_hpol_run34_pp.mat'  # 3900:39900 120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][2100:18000,0:256].view('complex')\n",
    "# locations=53\n",
    "# records=300  \n",
    "# load_path='F:/NISTdata_H/Active Mobile/AAPlantD1_2GHz_TX1_vpol_run3_pp.mat'   # 6600:42600  120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][6600:24600,0:256].view('complex')\n",
    "# locations=60\n",
    "# records=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "seed = 0                        # random seed\n",
    "batch_size = 32                # batch size\n",
    "num_epoch = 30                  # the number of training epoch\n",
    "patience = 10                  # If no improvement in 'patience' epochs, early stop\n",
    "learning_rate = 0.0001         # learning rate\n",
    "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "k=1  #H为k+1个h\n",
    "nf=1 #参考CSI的数量+1\n",
    "index=[0,1]\n",
    "d=2  #eve在alice后面d-1个位置处尾随\n",
    "input_channels=4\n",
    "len_sequence = 256                  # the input dim of the model, you should not change the value\n",
    "output_dim=2\n",
    "mu=0.4\n",
    "std=0.1\n",
    "sw=0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creat a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import fft\n",
    "def convert_seq(h):\n",
    "    a=np.abs(h)\n",
    "    b=np.angle(h)\n",
    "    c=np.abs(fft.fft(h))\n",
    "    d=np.angle(fft.fft(h))\n",
    "    seq=np.concatenate((a,b,c,d),axis=0)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creatH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatHSeq_Alice(idx, k, nf):\n",
    "    H=np.zeros((k+nf,len_sequence)).astype(complex)\n",
    "    H=IQdata[idx-nf:idx+k]\n",
    "    H=H[index]\n",
    "    return  H.flatten()\n",
    "def creatHSeq_Eve(idx, k, nf, d):\n",
    "    H=np.zeros((k+nf,len_sequence)).astype(complex)\n",
    "    H[nf:k+nf,:]=IQdata[idx-d*records:idx+k-d*records]\n",
    "    H[0:nf,:]=IQdata[idx-nf:idx]\n",
    "    H=H[index]\n",
    "    return  H.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs=records*d\n",
    "num_dataall=locations*records-recs-10\n",
    "dataall_HimagA=np.zeros((num_dataall,len_sequence*(k+nf)*input_channels)).astype(float)\n",
    "dataall_HimagE=np.zeros((num_dataall,len_sequence*(k+nf)*input_channels)).astype(float)\n",
    "for i in range(recs,locations*records-10):\n",
    "    dataall_HimagA[i-recs,:]=convert_seq(creatHSeq_Alice(i,k=k,nf=nf))\n",
    "    dataall_HimagE[i-recs,:]=convert_seq(creatHSeq_Eve(i,k=k,nf=nf,d=d))\n",
    "\n",
    "dataall_TW=np.concatenate((dataall_HimagA,dataall_HimagE),axis=0)\n",
    "location=[i for i in range(2)]\n",
    "test_data=dataall_TW\n",
    "test_lab=[val for val in location for i in range(int(num_dataall))]\n",
    "train_data=dataall_TW[0:int(num_dataall*2):2]\n",
    "train_label=[val for val in location for i in range(int(num_dataall/2))]\n",
    "valid_data=dataall_TW[1:int(num_dataall*2):2]\n",
    "valid_label=[val for val in location for i in range(int(num_dataall/2))]\n",
    "\n",
    "del dataall_HimagA, dataall_HimagE, dataall_TW\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                              min_samples_leaf=10, \n",
    "                              max_leaf_nodes=20, \n",
    "                              random_state=220)\n",
    "bagging = BaggingClassifier(tree,\n",
    "                            n_estimators=19, \n",
    "                            random_state=220)\n",
    "\n",
    "_exp_name = \"H_BT_hrun4_sample\"   \n",
    "# ---training---\n",
    "bagging.fit(train_data, train_label)\n",
    "tra_label=bagging.predict(train_data)       \n",
    "acc=accuracy_score(train_label,tra_label)\n",
    "# Print the information.\n",
    "print(f\"[ Train ] , acc = {acc:.5f}\")\n",
    "joblib.dump(bagging, f\"{_exp_name}_best.m\") # only save best to prevent output memory exceed error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = joblib.load(f\"{_exp_name}_best.m\")\n",
    "tes_label=model_best.predict(test_data)\n",
    "accuracy=accuracy_score(tes_label,test_lab)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "error_train=np.array(tra_label)-np.array(train_label)\n",
    "plt.figure(1)\n",
    "plt.plot(error_train, linestyle=\"--\", label=\"train\")\n",
    "plt.xlabel('Records')\n",
    "plt.ylabel('Error')\n",
    "plt.show\n",
    "error_test=np.array(tes_label)-np.array(test_lab)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(2)\n",
    "plt.plot(error_test, linestyle=\"--\")\n",
    "plt.xlabel('Records')\n",
    "plt.ylabel('Error')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
