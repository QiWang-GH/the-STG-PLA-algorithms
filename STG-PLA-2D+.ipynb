{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "Note: data is the three scale channel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "load_path='F:/wangqi/nistdataset/AAPlantD1_2GHz_TX1_hpol_run4_pp.mat'\n",
    "load_mat=h5py.File(load_path,'r')\n",
    "IQdata=load_mat['IQdata'][3600:21600,0:256].view('complex')\n",
    "locations=60\n",
    "records=300\n",
    "# load_path='F:/wangqi/nistdataset/AAPlantD1_2GHz_TX1_vpol_run3_pp.mat'   # 6600:42600  120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][6600:42600,0:256].view('complex')\n",
    "# locations=120\n",
    "# records=300\n",
    "# load_path='F:/wangqi/nistdataset/AAPlantD3_2GHz_TX2b_vpol_run32_pp.mat'  # 3900:39900 120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][3900:39900,0:256].view('complex')\n",
    "# locations=120\n",
    "# records=300\n",
    "# load_path='F:/wangqi/nistdataset/AAPlantD3_2GHz_TX2b_hpol_run34_pp.mat'  # 3900:39900 120\n",
    "# load_mat=h5py.File(load_path,'r')\n",
    "# IQdata=load_mat['IQdata'][2100:33900,0:256].view('complex')\n",
    "# locations=106\n",
    "# records=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "seed = 0                        # random seed\n",
    "batch_size = 32                # batch size\n",
    "num_epoch = 100                  # the number of training epoch\n",
    "patience = 5                  # If no improvement in 'patience' epochs, early stop\n",
    "learning_rate = 0.001       # learning rate\n",
    "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "k=1  #H为k+1个h\n",
    "nf=2 #参考CSI的数量+1\n",
    "index=[0,1,2]\n",
    "# index=[0,1,3,2]\n",
    "# index=[0,1,3,2,4]\n",
    "# index=[0,1,4,2,5,3,6]\n",
    "# index=[0,1,4,2,5,3,6]\n",
    "d=2  #eve在alice后面d-1个位置处尾随\n",
    "input_channels=4\n",
    "len_sequence = 256                  # the input dim of the model, you should not change the value\n",
    "hidden_layers = 1               # the number of hidden layers\n",
    "hidden_dim = 64                # the hidden dim\n",
    "output_dim=2\n",
    "mu=0.4\n",
    "std=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatHimag_Alice(idx, k, nf):\n",
    "    H=np.zeros((k+nf,len_sequence)).astype(complex)\n",
    "    H=IQdata[idx-nf:idx+k]\n",
    "    return  np.transpose(H[index])\n",
    "def creatHimag_Eve(idx, k, nf, d):\n",
    "    H=np.zeros((k+nf,len_sequence)).astype(complex)\n",
    "    H[nf:k+nf,:]=IQdata[idx-d*records:idx+k-d*records]\n",
    "    H[0:nf,:]=IQdata[idx-nf:idx]\n",
    "    return  np.transpose(H[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs=records*d\n",
    "num_dataall=locations*records-recs-10\n",
    "dataall_HimagA=np.zeros((num_dataall,len_sequence, k+nf)).astype(complex)\n",
    "dataall_HimagE=np.zeros((num_dataall,len_sequence, k+nf)).astype(complex)\n",
    "for i in range(recs,locations*records-10):\n",
    "    dataall_HimagA[i-recs,:,:]=creatHimag_Alice(i,k=k,nf=nf)\n",
    "    dataall_HimagE[i-recs,:,:]=creatHimag_Eve(i,k=k,nf=nf,d=d)\n",
    "\n",
    "dataall_TW=np.concatenate((dataall_HimagA,dataall_HimagE),axis=0)\n",
    "location=[i for i in range(2)]\n",
    "test_data=dataall_TW\n",
    "test_lab=[val for val in location for i in range(int(num_dataall))]\n",
    "train_data=dataall_TW[0:int(num_dataall*2):2]\n",
    "train_label=[val for val in location for i in range(int(num_dataall/2))]\n",
    "valid_data=dataall_TW[1:int(num_dataall*2):2]\n",
    "valid_label=[val for val in location for i in range(int(num_dataall/2))]\n",
    "\n",
    "del dataall_HimagA, dataall_HimagE, dataall_TW\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creat a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import fft\n",
    "def convert_pic(h):\n",
    "    width, height=h.shape  # width=128,height=k+nf\n",
    "    img=np.zeros([input_channels,len_sequence,height-1]).astype(np.float32)\n",
    "    for i in range(1,height):\n",
    "        img[0,:,i-1]=np.abs(h[:,i]*np.conj(h[:,0]))\n",
    "        img[1,:,i-1]=np.angle(h[:,i]*np.conj(h[:,0]))\n",
    "    hf=fft.fft2(h)\n",
    "    for i in range(1,height):\n",
    "        img[2,:,i-1]=np.abs(hf[:,i]*np.conj(hf[:,0]))\n",
    "        img[3,:,i-1]=np.angle(hf[:,i]*np.conj(hf[:,0]))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class hDataset(Dataset):\n",
    "    def __init__(self, k, X, y=None):\n",
    "        super(hDataset).__init__()\n",
    "        self.data = X\n",
    "        self.k = k\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        h = self.data[idx]\n",
    "        h = convert_pic(h)\n",
    "        if self.label is not None:\n",
    "            return h, self.label[idx]\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import resnet34\n",
    "import os\n",
    "# get dataset\n",
    "train_set = hDataset(k,train_data, train_label)\n",
    "valid_set = hDataset(k,valid_data, valid_label)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "# del train_data, valid_data, valid_label\n",
    "# gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')\n",
    "# create model, define a loss function, and optimizer\n",
    "net = resnet34()\n",
    "in_channel = net.fc.in_features\n",
    "net.fc = nn.Linear(in_channel, output_dim)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# criterion = nn.BCELoss() \n",
    "params = [p for p in net.parameters() if p.requires_grad]\n",
    "# optimizer = optim.AdamW(params, lr=learning_rate)\n",
    "optimizer = optim.Adam(params, lr=learning_rate, weight_decay=1e-5)\n",
    "# optimizer = optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import sys\n",
    "stale=0\n",
    "best_acc = 0.0\n",
    "_exp_name = \"Corrm_hrun4_resnettwi_sample\"\n",
    "train_losses=[]\n",
    "train_accss=[]\n",
    "valid_losses=[]\n",
    "valid_accss=[]\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    net.train()\n",
    "    train_loss=[]\n",
    "    train_accs=[]\n",
    "# ---training---\n",
    "    # train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    # for batch in enumerate(train_bar):\n",
    "    for batch in train_loader:    \n",
    "        H, labels =batch\n",
    "        H = H.to(device)\n",
    "        labels = labels.to(device)\n",
    "   \n",
    "        optimizer.zero_grad()\n",
    "        logits = net(H.to(device))\n",
    "        loss =criterion(logits, labels.to(device))\n",
    "        loss.backward()\n",
    "        # grad_norm=nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc=(logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        \n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        \n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accss.append(np.array(train_acc.cpu()))\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{num_epoch:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "# ---validation---\n",
    "    net.eval()\n",
    "    valid_loss=[]\n",
    "    valid_accs=[]\n",
    "\n",
    "    # for batch in tqdm(valid_loader):\n",
    "    for batch in valid_loader:\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        H, labels = batch\n",
    "        #imgs = imgs.half()\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = net(H.to(device))\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "        #break\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accss.append(np.array(valid_acc.cpu()))\n",
    "    # Print the information.\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{num_epoch:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")        \n",
    "\n",
    "    # update logs\n",
    "    if valid_acc > best_acc:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{num_epoch:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    else:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{num_epoch:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "\n",
    "    # save models\n",
    "    # if epoch % 50 == 0:\n",
    "    if valid_acc > best_acc:\n",
    "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "        torch.save(net.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "        best_acc = valid_acc\n",
    "        stale = 0\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale > patience:\n",
    "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Acc show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_losses, linestyle=\"--\", label=\"train\")\n",
    "plt.plot(valid_losses, linestyle=\"-\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(train_accss, linestyle=\"--\", label=\"train\")\n",
    "plt.plot(valid_accss, linestyle=\"-\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_set = hDataset(k, test_data, test_lab)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "model_best = resnet34(num_classes=output_dim).to(device)\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()\n",
    "accuracy=1 - np.count_nonzero(np.array(prediction)-np.array(test_lab))/len(prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=np.array(prediction)-np.array(test_lab)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot(error, linestyle=\"--\")\n",
    "# plt.legend(loc=\"best\")\n",
    "plt.xlabel('Records')\n",
    "plt.ylabel('Error')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10a56fe35cef5e20a6d2ddfc0a4e0d073b59b974d8a919d683845127505c73a2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorchgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
